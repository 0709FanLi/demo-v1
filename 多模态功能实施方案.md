# 多模态功能实施方案

## 📋 目标

为系统添加多模态支持，能够处理：
- ✅ **图片输入**：用户上传图片进行问答
- ✅ **图片知识库**：将图片作为知识存储
- ✅ **PDF 文档**：解析 PDF 并存入知识库
- ✅ **混合检索**：同时检索文本和图片

---

## 🎯 实施步骤总览

| 阶段 | 任务 | 预计时间 | 难度 |
|------|------|---------|------|
| **阶段1** | 环境准备与依赖安装 | 30分钟 | ⭐ 简单 |
| **阶段2** | 图片向量化服务 | 1-2小时 | ⭐⭐ 中等 |
| **阶段3** | PDF 解析服务 | 1-2小时 | ⭐⭐ 中等 |
| **阶段4** | 扩展知识库服务 | 2-3小时 | ⭐⭐⭐ 较难 |
| **阶段5** | API 接口扩展 | 1-2小时 | ⭐⭐ 中等 |
| **阶段6** | 前端界面改造 | 2-3小时 | ⭐⭐ 中等 |
| **阶段7** | 测试与优化 | 1-2小时 | ⭐⭐ 中等 |
| **总计** | | **8-15小时** | |

---

## 📦 阶段1：环境准备与依赖安装

### 1.1 需要安装的 Python 包

```bash
# 图片处理
pillow==10.2.0              # 图片基础操作
opencv-python==4.9.0.80     # 图片预处理

# 多模态模型
transformers==4.36.0        # Hugging Face 模型库
torch==2.1.0                # PyTorch（CLIP 依赖）
torchvision==0.16.0         # 图片处理

# PDF 处理
pymupdf==1.23.0             # PDF 解析（也叫 fitz）
pdf2image==1.17.0           # PDF 转图片
pytesseract==0.3.10         # OCR（可选）

# 文件处理
python-magic==0.4.27        # 文件类型检测
```

### 1.2 系统依赖（如需 OCR）

```bash
# macOS
brew install tesseract
brew install poppler  # pdf2image 需要

# 验证安装
tesseract --version
pdfinfo -v
```

### 1.3 模型下载

需要下载的模型：
- **CLIP 模型**：`openai/clip-vit-base-patch32` (~600MB)
- **或使用中文优化版**：`OFA-Sys/chinese-clip-vit-base-patch16` (~800MB)

模型会自动下载到：`~/.cache/huggingface/`

---

## 🖼️ 阶段2：图片向量化服务

### 2.1 创建多模态编码器

**新建文件**：`backend/src/services/multimodal_encoder.py`

**功能**：
```python
class MultiModalEncoder:
    """多模态编码器（文本+图片）"""
    
    def __init__(self):
        # 加载 CLIP 模型
        self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
        self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
    
    def encode_text(self, text: str) -> np.ndarray:
        """文本编码（512维）"""
        pass
    
    def encode_image(self, image_path: str) -> np.ndarray:
        """图片编码（512维）"""
        pass
    
    def encode_image_from_bytes(self, image_bytes: bytes) -> np.ndarray:
        """从字节流编码图片"""
        pass
```

**关键点**：
- ✅ CLIP 模型输出 512 维向量
- ✅ 文本和图片在同一向量空间
- ✅ 可以直接计算跨模态相似度

---

## 📄 阶段3：PDF 解析服务

### 3.1 创建 PDF 处理器

**新建文件**：`backend/src/services/pdf_processor.py`

**功能**：
```python
class PDFProcessor:
    """PDF 文档处理器"""
    
    def extract_text(self, pdf_path: str) -> List[str]:
        """提取 PDF 文本（按页）"""
        pass
    
    def extract_images(self, pdf_path: str) -> List[bytes]:
        """提取 PDF 中的图片"""
        pass
    
    def convert_to_images(self, pdf_path: str) -> List[Image]:
        """将 PDF 页面转为图片（用于 OCR）"""
        pass
    
    def process_pdf(self, pdf_path: str) -> Dict:
        """完整处理：文本+图片"""
        return {
            'texts': [...],      # 文本内容
            'images': [...],     # 图片列表
            'metadata': {...}    # 元数据
        }
```

**处理流程**：
1. 尝试提取文本（原生文本）
2. 如果文本为空，使用 OCR
3. 提取所有图片
4. 分别向量化存储

---

## 🗄️ 阶段4：扩展知识库服务

### 4.1 修改 Milvus Collection Schema

**当前 Schema**（384维，纯文本）：
```python
fields = [
    FieldSchema(name='id', dtype=DataType.VARCHAR, is_primary=True),
    FieldSchema(name='content', dtype=DataType.VARCHAR),
    FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=384),  # 当前
    FieldSchema(name='category', dtype=DataType.VARCHAR),
]
```

**新 Schema**（512维，多模态）：
```python
fields = [
    FieldSchema(name='id', dtype=DataType.VARCHAR, max_length=100, is_primary=True),
    FieldSchema(name='content', dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=512),  # 改为 512
    FieldSchema(name='category', dtype=DataType.VARCHAR, max_length=100),
    
    # 新增字段
    FieldSchema(name='content_type', dtype=DataType.VARCHAR, max_length=20),  # text/image/pdf
    FieldSchema(name='file_path', dtype=DataType.VARCHAR, max_length=500),    # 文件路径
    FieldSchema(name='file_size', dtype=DataType.INT64),                      # 文件大小
    FieldSchema(name='image_url', dtype=DataType.VARCHAR, max_length=500),    # 图片URL（可选）
    FieldSchema(name='parent_id', dtype=DataType.VARCHAR, max_length=100),    # 父文档ID（PDF页面）
]
```

### 4.2 数据迁移策略

**问题**：现有数据是 384 维，新模型是 512 维

**方案A**：清空重建（推荐，数据量小）
```python
# 1. 备份现有数据
# 2. 删除旧 Collection
# 3. 创建新 Collection（512维）
# 4. 重新添加数据
```

**方案B**：双 Collection 并存
```python
# knowledge_base_v1 (384维，旧数据)
# knowledge_base_v2 (512维，新数据)
# 检索时同时查询两个
```

### 4.3 扩展 KnowledgeService

**新增方法**：
```python
class KnowledgeService:
    # 现有方法
    async def add_knowledge(self, knowledge: KnowledgeCreate) -> str:
        """添加文本知识（已有）"""
        pass
    
    # 新增方法
    async def add_image(
        self,
        image_file: UploadFile,
        category: str,
        description: str = ""
    ) -> str:
        """添加图片知识"""
        # 1. 保存图片到本地/对象存储
        # 2. 使用 CLIP 编码图片
        # 3. 存入 Milvus
        pass
    
    async def add_pdf(
        self,
        pdf_file: UploadFile,
        category: str,
        extract_images: bool = True
    ) -> List[str]:
        """添加 PDF 文档"""
        # 1. 解析 PDF（文本+图片）
        # 2. 分别向量化
        # 3. 关联存储（parent_id）
        pass
    
    async def search_multimodal(
        self,
        query: str = None,
        image: UploadFile = None,
        content_type: str = None,
        top_k: int = 5
    ) -> List[SearchResult]:
        """多模态检索"""
        # 1. 如果有文本，编码文本
        # 2. 如果有图片,编码图片
        # 3. 混合检索或单独检索
        pass
```

---

## 🔌 阶段5：API 接口扩展

### 5.1 新增知识库接口

**文件**：`backend/src/api/routers/knowledge.py`

**新增接口**：

```python
@router.post('/upload-image')
async def upload_image(
    file: UploadFile = File(...),
    category: str = Form(...),
    description: str = Form(""),
):
    """上传图片到知识库"""
    pass

@router.post('/upload-pdf')
async def upload_pdf(
    file: UploadFile = File(...),
    category: str = Form(...),
    extract_images: bool = Form(True),
):
    """上传 PDF 到知识库"""
    pass

@router.post('/search-by-image')
async def search_by_image(
    file: UploadFile = File(...),
    top_k: int = Form(5),
):
    """以图搜图"""
    pass
```

### 5.2 修改 RAG 接口

**文件**：`backend/src/api/routers/chat.py`

**增强现有接口**：

```python
@router.post('/chat-with-image')
async def chat_with_image(
    question: str = Form(...),
    image: UploadFile = File(None),  # 可选图片
    use_knowledge_base: bool = Form(True),
):
    """图文混合对话"""
    # 1. 检索知识库（文本+图片）
    # 2. 调用多模态 LLM（qwen-vl-max）
    # 3. 返回回答
    pass
```

---

## 🎨 阶段6：前端界面改造

### 6.1 添加文件上传组件

**新建**：`frontend/src/components/FileUpload.tsx`

**功能**：
- ✅ 支持拖拽上传
- ✅ 图片预览
- ✅ PDF 预览
- ✅ 进度条显示
- ✅ 文件类型验证

### 6.2 改造聊天界面

**修改**：`frontend/src/App.tsx`

**新增功能**：
1. **图片上传按钮**
   - 点击上传图片
   - 显示图片预览
   - 可删除重选

2. **消息类型扩展**
   ```typescript
   interface Message {
     role: 'user' | 'assistant';
     content: string;
     image?: string;      // 新增：图片URL
     imageFile?: File;    // 新增：图片文件
   }
   ```

3. **图片消息渲染**
   ```tsx
   {message.image && (
     <img src={message.image} alt="用户上传" />
   )}
   ```

### 6.3 添加知识库管理功能

**新建**：`frontend/src/components/MultimodalKnowledge.tsx`

**功能**：
- ✅ 上传图片到知识库
- ✅ 上传 PDF 到知识库
- ✅ 查看已上传文件
- ✅ 删除文件

---

## 🔄 阶段7：测试与优化

### 7.1 功能测试

**文本知识库测试**：
```bash
# 添加文本知识
curl -X POST http://localhost:8001/api/v1/knowledge/add \
  -H "Content-Type: application/json" \
  -d '{"content": "产品图片展示", "category": "产品"}'

# 检索
curl -X GET "http://localhost:8001/api/v1/knowledge/search?query=产品"
```

**图片知识库测试**：
```bash
# 上传图片
curl -X POST http://localhost:8001/api/v1/knowledge/upload-image \
  -F "file=@product.jpg" \
  -F "category=产品图片" \
  -F "description=新款产品"

# 以图搜图
curl -X POST http://localhost:8001/api/v1/knowledge/search-by-image \
  -F "file=@query.jpg" \
  -F "top_k=5"
```

**PDF 测试**：
```bash
# 上传 PDF
curl -X POST http://localhost:8001/api/v1/knowledge/upload-pdf \
  -F "file=@manual.pdf" \
  -F "category=产品手册"
```

**多模态对话测试**：
```bash
# 图文对话
curl -X POST http://localhost:8001/api/v1/chat/chat-with-image \
  -F "question=这是什么产品？" \
  -F "image=@product.jpg"
```

### 7.2 性能优化

**图片处理优化**：
```python
# 1. 图片压缩（减少存储）
def compress_image(image: Image, max_size: tuple = (800, 800)):
    image.thumbnail(max_size, Image.LANCZOS)
    return image

# 2. 批量编码（提高效率）
def encode_images_batch(images: List[Image], batch_size: int = 32):
    for i in range(0, len(images), batch_size):
        batch = images[i:i+batch_size]
        yield model.encode(batch)

# 3. 缓存模型（避免重复加载）
@lru_cache(maxsize=1)
def get_clip_model():
    return CLIPModel.from_pretrained(...)
```

**检索优化**：
```python
# 1. 使用更快的索引
index_params = {
    'metric_type': 'COSINE',
    'index_type': 'HNSW',  # 比 IVF_FLAT 更快
    'params': {'M': 16, 'efConstruction': 256}
}

# 2. 分类过滤
expr = f'content_type == "image" AND category == "产品"'

# 3. 混合检索权重
text_weight = 0.6
image_weight = 0.4
final_score = text_score * text_weight + image_score * image_weight
```

---

## 📊 数据结构设计

### Collection 设计（最终版）

```python
knowledge_base_multimodal = {
    'name': 'knowledge_base',
    'fields': [
        {'name': 'id', 'type': 'VARCHAR', 'primary': True},
        {'name': 'content', 'type': 'VARCHAR'},           # 文本内容或描述
        {'name': 'vector', 'type': 'FLOAT_VECTOR', 'dim': 512},
        {'name': 'content_type', 'type': 'VARCHAR'},      # text/image/pdf
        {'name': 'category', 'type': 'VARCHAR'},
        {'name': 'file_path', 'type': 'VARCHAR'},         # 文件存储路径
        {'name': 'file_size', 'type': 'INT64'},
        {'name': 'created_at', 'type': 'VARCHAR'},
        {'name': 'metadata', 'type': 'JSON'},             # 额外元数据
    ]
}
```

### 文件存储结构

```
backend/
├── data/
│   ├── images/           # 图片存储
│   │   ├── 2025/
│   │   │   └── 10/
│   │   │       └── abc123.jpg
│   ├── pdfs/             # PDF 存储
│   │   └── 2025/
│   │       └── 10/
│   │           └── doc456.pdf
│   └── thumbnails/       # 缩略图
│       └── abc123_thumb.jpg
```

---

## 🎯 实施优先级建议

### 优先级1（核心功能）- 必须实现
1. ✅ 安装依赖
2. ✅ 图片向量化（CLIP）
3. ✅ 扩展 Milvus Schema
4. ✅ 图片上传 API
5. ✅ 前端图片上传

**预计时间**：4-6 小时

### 优先级2（增强功能）- 推荐实现
1. ✅ PDF 解析
2. ✅ 以图搜图
3. ✅ 多模态对话
4. ✅ 知识库管理界面

**预计时间**：4-6 小时

### 优先级3（优化功能）- 可选实现
1. ⭐ OCR 支持
2. ⭐ 图片压缩
3. ⭐ 缓存优化
4. ⭐ 批量上传

**预计时间**：2-3 小时

---

## 🚀 快速开始建议

### 方案A：完整实施（推荐）

按照 7 个阶段依次实施，最终获得完整的多模态功能。

**时间**：8-15 小时  
**适合**：有充足时间，想要完整功能

### 方案B：最小可行方案（MVP）

只实现核心功能：
1. 安装 CLIP 模型
2. 图片向量化
3. 图片上传 API
4. 简单的前端上传

**时间**：4-6 小时  
**适合**：快速验证概念

### 方案C：渐进式实施

分多次实施：
- **第1次**：图片功能（2-3小时）
- **第2次**：PDF 功能（2-3小时）
- **第3次**：界面优化（2-3小时）

**时间**：分散进行  
**适合**：时间碎片化

---

## 📋 检查清单

### 开始前检查
- [ ] Docker 运行正常
- [ ] Milvus 运行正常
- [ ] 后端服务正常
- [ ] 前端服务正常
- [ ] 有测试图片和 PDF 文件

### 实施中检查
- [ ] 依赖安装成功
- [ ] CLIP 模型下载完成
- [ ] Milvus Schema 创建成功
- [ ] API 测试通过
- [ ] 前端功能正常

### 完成后检查
- [ ] 可以上传图片
- [ ] 可以以图搜图
- [ ] 可以上传 PDF
- [ ] 多模态对话正常
- [ ] 性能可接受

---

## 💡 重要提示

### 1. 向量维度变化

**关键决策**：
- 当前：384 维（sentence-transformers）
- 改为：512 维（CLIP）

**影响**：
- ❌ 不兼容！必须重建 Collection
- ✅ 但数据量小，影响不大

### 2. 模型选择

**CLIP 模型对比**：

| 模型 | 大小 | 速度 | 中文支持 | 推荐 |
|------|------|------|---------|------|
| openai/clip-vit-base-patch32 | 600MB | 快 | 一般 | ⭐⭐⭐⭐ |
| openai/clip-vit-large-patch14 | 1.7GB | 慢 | 一般 | ⭐⭐⭐ |
| OFA-Sys/chinese-clip-vit-base | 800MB | 快 | 好 | ⭐⭐⭐⭐⭐ |

**建议**：先用 base 模型验证，需要时升级。

### 3. 存储考虑

**文件存储选项**：
- **本地存储**（当前）：简单，适合开发
- **MinIO**（推荐）：Milvus 自带，已有容器
- **阿里云 OSS**：生产环境

### 4. 性能预期

**处理时间估算**：
- 图片编码：~100ms/张
- PDF 解析：~1-5秒/页
- 向量检索：~10-50ms

---

## 🎓 学习资源

### CLIP 模型
- 论文：https://arxiv.org/abs/2103.00020
- Hugging Face：https://huggingface.co/openai/clip-vit-base-patch32

### Milvus 多模态
- 官方教程：https://milvus.io/docs/image_similarity_search.md
- 最佳实践：https://milvus.io/docs/multimodal_rag.md

### PDF 处理
- PyMuPDF 文档：https://pymupdf.readthedocs.io/
- PDF2Image：https://github.com/Belval/pdf2image

---

## ✅ 总结

### 核心改变

1. **模型层**：添加 CLIP 多模态编码器
2. **数据层**：Milvus Schema 扩展（512维）
3. **服务层**：扩展知识库服务
4. **API层**：新增上传和检索接口
5. **前端层**：添加文件上传功能

### 工作量估算

- **最小方案**：4-6 小时
- **标准方案**：8-12 小时
- **完整方案**：12-15 小时

### 建议

**推荐从 MVP 开始**：
1. 先实现图片上传和检索
2. 验证效果
3. 再扩展 PDF 和优化功能

---

**准备好开始了吗？告诉我您想从哪个阶段开始！** 🚀

