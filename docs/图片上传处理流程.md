# 图片上传处理流程说明

## 📸 图片上传后的处理流程

### 1. 前端处理
- 用户选择图片后，图片在前端预览
- 点击发送时，调用 `chatWithImage` API
- 将图片文件和问题文本一起发送到后端

### 2. 后端接口处理 (`/api/v1/chat/with-image`)

**步骤 1：图片预处理**
```python
# 读取图片数据
image_bytes = await image.read()

# 压缩图片（最大尺寸 1024px）
resized_image = resize_image(image_bytes, max_size=1024)

# 转换为 Base64 编码
image_base64 = image_to_base64(resized_image)
```

**步骤 2：构建请求**
- 将图片 Base64 编码和问题文本封装到 `ChatRequest`
- 设置 `use_knowledge_base=True`（默认使用知识库）

### 3. RAG 服务处理 (`RAGService.chat()`)

**如果有图片，会执行以下流程：**

#### 3.1 知识库检索（可选）
- 如果 `use_knowledge_base=True`，会根据问题文本检索相关知识
- 检索到的知识会被添加到提示词中

#### 3.2 调用多模态大模型
```python
# 检测到有图片
if has_image:
    # 调用阿里云多模态模型
    answer = await self.aliyun_service.chat_with_image(
        text=full_prompt,  # 包含知识库内容的完整提示词
        image_base64=request.image_base64,  # 图片 Base64
        history=None,
    )
    model_used = settings.default_vl_model  # 默认：qwen-vl-max
```

#### 3.3 阿里云多模态 API 调用
- 使用 `MultiModalConversation.call()` 调用阿里云通义千问视觉模型
- 模型会同时理解图片内容和文本问题
- 返回文本回答

### 4. 当前配置

**使用的模型：**
- 图片 + 文本对话：`qwen-vl-max`（通义千问视觉模型）
- 纯文本对话：`qwen-plus`（通义千问文本模型）

**处理流程：**
```
用户上传图片 + 问题
    ↓
后端：压缩图片 → Base64 编码
    ↓
RAG服务：检索知识库（如果有）
    ↓
构建提示词（包含知识库内容 + 用户问题）
    ↓
调用阿里云多模态模型（qwen-vl-max）
    ↓
模型分析图片 + 文本，生成回答
    ↓
返回给前端显示
```

### 5. 应用场景

**图片分析能力：**
- 📊 分析检查报告（如体检报告、血检报告）
- 📈 分析图表和数据可视化
- 🖼️ 识别医疗相关的图片内容
- 📋 分析文档截图

**结合知识库：**
- 图片内容 + 知识库检索 → 提供更准确的建议
- 例如：上传体检报告图片，结合知识库中的健康知识，给出专业建议

### 6. 注意事项

1. **图片大小限制**：自动压缩到最大 1024px
2. **格式支持**：支持常见图片格式（jpeg, png, gif 等）
3. **API 费用**：多模态模型调用会产生费用
4. **响应时间**：图片分析通常比纯文本对话耗时更长

### 7. 配置位置

- 模型配置：`backend/src/config/settings.py`
  - `default_vl_model`: 视觉语言模型（当前：qwen-vl-max）
  - `default_llm_model`: 文本模型（当前：qwen-plus）

