# RAG智能对话系统 - 详细技术说明

## 📋 目录

1. [项目概述](#项目概述)
2. [核心功能](#核心功能)
3. [技术架构](#技术架构)
4. [大模型调用详解](#大模型调用详解)
5. [数据库设计](#数据库设计)
6. [RAG实现原理](#rag实现原理)
7. [启动方式](#启动方式)
8. [API接口说明](#api接口说明)

---

## 项目概述

这是一个基于**阿里云通义千问大模型**的**抗衰老专家咨询系统**，采用 RAG（检索增强生成）技术架构。

### 核心特点

- 🧬 **抗衰老专家定位**：提供基于科学证据的抗衰老建议和健康管理方案
- 📚 **专业知识库**：整合抗衰老领域的科学文献、临床研究和最新进展
- 🔍 **智能语义检索**：使用向量数据库快速匹配相关研究和专业知识
- 🖼️ **多模态输入**：支持文本和图片（如检查报告、身体指标）输入
- 🎯 **结构化专家提示词**：确保回答专业、严谨、易理解
- 💻 **企业级技术栈**：Milvus + FastAPI + React，性能稳定可扩展
- 📱 **移动端响应式**：随时随地获取专家建议

---

## 核心功能

### 1. 知识库管理

**功能说明**：
- 动态添加、删除、查询知识条目
- 自动文本分块和向量化
- 支持分类管理和元数据标注
- 批量导入知识

**技术实现**：
- 使用 Milvus 作为向量数据库（企业级）
- Sentence-Transformers 进行文本向量化
- 支持语义相似度检索（Top-K）
- 支持分布式部署和海量数据

### 2. RAG智能问答

**功能说明**：
- 基于知识库的上下文增强回答
- 自动检索相关知识并构建提示词
- 返回答案置信度和知识来源
- 支持历史对话上下文

**技术实现**：
- 向量检索 + 大模型生成
- 结构化提示词模板
- 置信度自动评估

### 3. 多模态对话

**功能说明**：
- 支持图片上传和识别
- 图文混合输入
- 自动图片压缩和Base64编码

**技术实现**：
- 使用阿里云通义千问-VL多模态模型
- PIL图片处理
- Base64编码传输

---

## 技术架构

### 整体架构图

```
┌─────────────────────────────────────────────────────────┐
│                    前端 (React)                          │
│  - 聊天界面  - 知识库管理  - 图片上传  - 历史记录       │
└───────────────────────┬─────────────────────────────────┘
                        │ HTTP REST API
                        ▼
┌─────────────────────────────────────────────────────────┐
│                FastAPI 路由层                            │
│  /api/v1/chat/          - RAG对话接口                   │
│  /api/v1/knowledge/     - 知识库管理接口                │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│                   服务层 (Services)                      │
│  ┌───────────────────────────────────────────────┐      │
│  │  RAGService (核心编排)                         │      │
│  │  - 接收用户问题                                │      │
│  │  - 调用知识检索                                │      │
│  │  - 构建提示词                                  │      │
│  │  - 调用大模型                                  │      │
│  │  - 评估置信度                                  │      │
│  └──────────┬──────────────────┬──────────────────┘      │
│            │                  │                         │
│  ┌─────────▼─────────┐  ┌────▼───────────────┐        │
│  │ KnowledgeService  │  │  AliyunService     │        │
│  │ (知识库管理)       │  │  (大模型调用)       │        │
│  │                   │  │                    │        │
│  │ - 文本向量化       │  │ - API密钥管理       │        │
│  │ - 向量检索         │  │ - 重试机制         │        │
│  │ - CRUD操作        │  │ - 异步调用         │        │
│  └─────────┬─────────┘  └────────────────────┘        │
└────────────┼──────────────────────────────────────────┘
             │
             ▼
┌─────────────────────────────────────────────────────────┐
│                   数据层                                 │
│  ┌─────────────────┐  ┌──────────────────────────┐     │
│  │  Milvus 向量库  │  │  阿里云通义千问 API       │     │
│  │  (企业级)        │  │  - qwen-max (文本)       │     │
│  │                 │  │  - qwen-vl-max (图文)    │     │
│  │  部署方式:       │  │                          │     │
│  │  Docker Compose │  │  API Key: sk-8b6d...     │     │
│  │  端口: 19530    │  │                          │     │
│  └─────────────────┘  └──────────────────────────┘     │
└─────────────────────────────────────────────────────────┘
```

### 技术栈

#### 后端
| 技术 | 版本 | 用途 |
|------|------|------|
| Python | 3.11.7 | 编程语言 |
| FastAPI | 0.109.0 | Web框架 |
| Uvicorn | 0.27.0 | ASGI服务器 |
| **Milvus** | **2.4.0** | **向量数据库（企业级）** |
| PyMilvus | 2.4.0 | Milvus Python SDK |
| Sentence-Transformers | 2.3.1 | 文本向量化 |
| DashScope | 1.14.1 | 阿里云SDK |
| Pydantic | 2.5.3 | 数据验证 |
| NumPy | 1.26.4 | 数值计算 |
| Docker | 最新 | 容器化部署 |

#### 前端
| 技术 | 版本 | 用途 |
|------|------|------|
| React | 18.2.0 | UI框架 |
| TypeScript | 4.9.5 | 类型安全 |
| Axios | 1.6.5 | HTTP客户端 |

---

## 大模型调用详解

### 1. 使用的模型

#### 文本对话模型
- **模型名称**: `qwen-max`
- **供应商**: 阿里云通义千问
- **能力**: 纯文本理解和生成
- **上下文长度**: 支持较长上下文
- **用途**: RAG对话、知识问答

#### 多模态模型
- **模型名称**: `qwen-vl-max`  
- **供应商**: 阿里云通义千问
- **能力**: 图文混合理解
- **用途**: 图片识别、图文问答

### 2. API调用配置

**配置文件**: `backend/env_template.txt`

```bash
# 阿里云API密钥
DASHSCOPE_API_KEY=sk-8b6db5929e244a159deb8e77b08bcf5b

# 模型配置
DEFAULT_LLM_MODEL=qwen-max        # 默认文本模型
DEFAULT_VL_MODEL=qwen-vl-max      # 默认多模态模型
MAX_TOKENS=2000                   # 最大生成token数
TEMPERATURE=0.7                   # 温度参数（创造性）
```

### 3. 调用流程

#### 纯文本对话流程

```python
# 文件: backend/src/services/aliyun_service.py

async def chat(self, messages, model=None):
    """
    1. 格式化消息
    messages = [
        {'role': 'user', 'content': '用户问题'}
    ]
    
    2. 调用API
    response = Generation.call(
        model='qwen-max',           # 模型名称
        messages=messages,          # 对话消息
        temperature=0.7,            # 温度参数
        max_tokens=2000,           # 最大token
        result_format='message'     # 返回格式
    )
    
    3. 解析响应
    answer = response.output.choices[0].message.content
    
    4. 返回结果
    return answer
    """
```

#### 图文对话流程

```python
# 文件: backend/src/services/aliyun_service.py

async def chat_with_image(self, text, image_url=None, image_base64=None):
    """
    1. 构建多模态内容
    content = [
        {'text': '用户文本'},
        {'image': 'data:image/jpeg;base64,xxx'}  # Base64图片
    ]
    
    2. 构建消息
    messages = [
        {
            'role': 'user',
            'content': content
        }
    ]
    
    3. 调用多模态API
    response = MultiModalConversation.call(
        model='qwen-vl-max',    # 多模态模型
        messages=messages
    )
    
    4. 提取回答
    answer = response.output.choices[0].message.content[0]['text']
    
    5. 返回结果
    return answer
    """
```

### 4. 重试机制

使用 `tenacity` 库实现自动重试：

```python
@retry(
    stop=stop_after_attempt(3),          # 最多重试3次
    wait=wait_exponential(                # 指数退避
        multiplier=1, 
        min=2,                            # 最小等待2秒
        max=10                            # 最大等待10秒
    ),
    retry=retry_if_exception_type(Exception),
    reraise=True                          # 重新抛出异常
)
async def chat(self, messages):
    # API调用逻辑
    pass
```

**重试策略**：
- 第1次失败：等待2秒后重试
- 第2次失败：等待4秒后重试
- 第3次失败：等待8秒后重试
- 3次都失败：抛出异常

### 5. Token使用监控

每次API调用都会记录token使用情况：

```python
logger.info(
    f'模型调用成功 - '
    f'模型: {model}, '
    f'输入token: {response.usage.input_tokens}, '
    f'输出token: {response.usage.output_tokens}'
)
```

**示例日志**：
```
模型调用成功 - 模型: qwen-max, 输入token: 169, 输出token: 59
```

---

## 数据库设计

### 1. 向量数据库 (Milvus)

**部署方式**: Docker Compose (Standalone 模式)

**访问地址**: `localhost:19530`

**组件**：
- `milvus-standalone`: 主服务
- `milvus-etcd`: 元数据存储
- `milvus-minio`: 对象存储

**Collection Schema**：

```python
{
    # 主键和内容
    "id": "doc_hash_chunk_0",              # 文档ID_分块索引 (VARCHAR, 主键)
    "content": "知识文本内容",             # 原始文本 (VARCHAR, max 65535)
    
    # 向量数据
    "vector": [0.1, 0.2, ..., 0.9],        # 384维向量 (FLOAT_VECTOR, dim=384)
    
    # 元数据字段
    "category": "售后政策",                # 分类 (VARCHAR)
    "created_at": "2024-01-01T00:00:00",   # 创建时间 (VARCHAR)
    "chunk_index": 0,                      # 分块索引 (INT64)
}
```

**索引配置**：
```python
{
    "metric_type": "COSINE",      # 余弦相似度
    "index_type": "IVF_FLAT",     # 索引类型
    "params": {"nlist": 128}      # 索引参数
}
```

**性能优势**：
- ✅ 支持 10 亿+向量规模
- ✅ 毫秒级检索速度
- ✅ 支持分布式部署
- ✅ 企业级高可用性
- ✅ 为未来多模态扩展做好准备

### 2. 向量化模型

**模型名称**: `paraphrase-multilingual-MiniLM-L12-v2`

**模型参数**：
- **维度**: 384
- **支持语言**: 50+（包括中文、英文等）
- **模型大小**: 471MB
- **速度**: ~5ms/句
- **提供商**: Sentence-Transformers

**工作原理**：
```python
# 文本 -> 向量
text = "我们支持7天无理由退货"
embedding = model.encode(text)  
# 输出: [0.123, -0.456, 0.789, ...] (384维)
```

### 3. 文本分块策略

**为什么需要分块**：
- 单个文本过长会影响检索精度
- 大模型有上下文长度限制

**分块参数**：
```python
CHUNK_SIZE = 500        # 每块500字符
CHUNK_OVERLAP = 50      # 块之间重叠50字符
```

**分块示例**：
```
原文: "我们支持7天无理由退货。退货时需要保持商品完好。退货流程：1.联系客服..."

分块后:
chunk_0: "我们支持7天无理由退货。退货时需要保持商品完好。退货流程：1.联系客服..."
chunk_1: "...退货流程：1.联系客服 2.填写退货单 3.寄回商品..."
         ^重叠部分^
```

### 4. 相似度计算

**算法**: 余弦相似度 (Cosine Similarity)

```python
# Milvus 使用余弦相似度计算向量距离
# 余弦相似度范围: [-1, 1]
# 1 = 完全相同, 0 = 正交, -1 = 完全相反

# Milvus 返回的是余弦距离 (cosine distance)
cosine_distance = 1 - cosine_similarity

# 转换为相似度分数 (0-1)
score = 1 - cosine_distance = cosine_similarity
```

**检索过程**：
```python
# 1. 用户问题向量化
query = "如何退货？"
query_embedding = model.encode(query)  # [0.1, 0.3, ...] (384维)

# 2. 在 Milvus 中搜索最相似的Top-K
results = collection.search(
    data=[query_embedding],           # 查询向量
    anns_field='vector',              # 向量字段名
    param={
        'metric_type': 'COSINE',      # 余弦相似度
        'params': {'nprobe': 10}      # 搜索参数
    },
    limit=3,                          # 返回最相似的3条
    output_fields=['content', 'category']  # 返回字段
)

# 3. 返回结果
[
    {"content": "退货政策...", "score": 0.95},
    {"content": "退货流程...", "score": 0.87},
    {"content": "退货条件...", "score": 0.76}
]
```

**Milvus 检索优势**：
- ✅ 使用 IVF_FLAT 索引，速度提升 3-5 倍
- ✅ 支持混合检索（向量+标量过滤）
- ✅ 自动负载均衡和查询优化

---

## Milvus 技术细节

### 为什么选择 Milvus？

**对比主流向量数据库**：

| 特性 | Milvus | ChromaDB | Pinecone | Weaviate |
|------|--------|----------|----------|----------|
| **性能** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **可扩展性** | 10亿+ | <100万 | 云端无限 | 百万级 |
| **部署方式** | 本地/云端 | 本地 | 仅云端 | 本地/云端 |
| **开源** | ✅ Apache 2.0 | ✅ Apache 2.0 | ❌ 商业 | ✅ BSD |
| **多模态支持** | ✅ 优秀 | ⚠️ 基础 | ✅ 良好 | ✅ 良好 |
| **成本** | 低（自托管） | 低 | 高（按量） | 中等 |
| **社区** | 活跃 | 中等 | 商业支持 | 活跃 |

**选择 Milvus 的理由**：
1. ✅ **性能卓越**：毫秒级检索，满足实时需求
2. ✅ **完全开源**：无供应商锁定，可自由定制
3. ✅ **企业级特性**：高可用、数据持久化、备份恢复
4. ✅ **本地部署**：数据安全可控，无隐私泄露风险
5. ✅ **多模态就绪**：为图片、视频等扩展做好准备
6. ✅ **活跃社区**：LF AI & Data 基金会项目，持续更新

### Milvus 架构

**Standalone 模式**（当前使用）：

```
┌─────────────────────────────────────────────┐
│          Milvus Standalone                  │
│  ┌──────────────────────────────────┐      │
│  │      Milvus 主服务               │      │
│  │  - 查询处理                      │      │
│  │  - 数据管理                      │      │
│  │  - 索引构建                      │      │
│  └──────────┬────────────┬──────────┘      │
│            │            │                  │
│  ┌─────────▼──────┐  ┌──▼─────────────┐   │
│  │  etcd          │  │  MinIO         │   │
│  │  (元数据存储)   │  │  (对象存储)     │   │
│  │  - Collection  │  │  - 向量数据     │   │
│  │  - Index       │  │  - 日志文件     │   │
│  └────────────────┘  └────────────────┘   │
└─────────────────────────────────────────────┘
```

**组件说明**：

1. **Milvus Standalone**：
   - 单机版，包含所有功能
   - 适合开发和中小规模应用
   - 内存需求：4-8GB
   
2. **etcd**：
   - 分布式键值存储
   - 存储 Collection Schema、索引信息
   - 保证元数据一致性

3. **MinIO**：
   - S3 兼容对象存储
   - 存储向量数据和日志
   - 支持数据持久化

### Collection 管理

**创建流程**：

```python
from pymilvus import Collection, FieldSchema, CollectionSchema, DataType

# 1. 定义字段
fields = [
    FieldSchema(name='id', dtype=DataType.VARCHAR, is_primary=True, max_length=256),
    FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=384),
    FieldSchema(name='content', dtype=DataType.VARCHAR, max_length=65535),
    FieldSchema(name='category', dtype=DataType.VARCHAR, max_length=256),
    FieldSchema(name='created_at', dtype=DataType.VARCHAR, max_length=256),
]

# 2. 创建 Schema
schema = CollectionSchema(
    fields=fields,
    description='知识库集合',
    enable_dynamic_field=True  # 支持动态字段
)

# 3. 创建 Collection
collection = Collection(
    name='knowledge_base',
    schema=schema,
    using='default',
    shards_num=2  # 分片数量
)

# 4. 创建索引
index_params = {
    'metric_type': 'COSINE',     # 余弦相似度
    'index_type': 'IVF_FLAT',    # 索引类型
    'params': {'nlist': 128}     # 聚类中心数
}
collection.create_index(
    field_name='vector',
    index_params=index_params
)

# 5. 加载到内存
collection.load()
```

### 索引类型选择

**Milvus 支持的索引**：

| 索引类型 | 速度 | 精度 | 内存 | 适用场景 |
|---------|------|------|------|---------|
| **FLAT** | 慢 | 100% | 高 | <1万条，最高精度 |
| **IVF_FLAT** | 快 | 95%+ | 中 | 10万-100万条 |
| **IVF_SQ8** | 快 | 90%+ | 低 | 节省内存 |
| **HNSW** | 极快 | 95%+ | 高 | 实时检索 |

**当前使用**：`IVF_FLAT`
- ✅ 速度快（3-5倍于 FLAT）
- ✅ 精度高（95%+ 召回率）
- ✅ 适合中等规模数据（<100万）

**参数说明**：
```python
'nlist': 128  # 聚类中心数量
# - 越大：索引构建越慢，检索越快
# - 建议：数据量的平方根（如 1万条 → nlist=100）
```

### 数据插入优化

**批量插入**：
```python
# 不推荐：逐条插入
for item in items:
    collection.insert([item])  # 慢！

# 推荐：批量插入
batch_size = 100
for i in range(0, len(items), batch_size):
    batch = items[i:i+batch_size]
    collection.insert(batch)
    
collection.flush()  # 确保数据写入磁盘
```

**性能对比**：
- 逐条插入：~50条/秒
- 批量插入（100条/批）：~2000条/秒
- **提升 40 倍！**

### 检索优化

**混合检索**（向量 + 标量过滤）：

```python
# 场景：只在"售后政策"分类中检索
results = collection.search(
    data=[query_vector],
    anns_field='vector',
    param={'metric_type': 'COSINE', 'params': {'nprobe': 10}},
    limit=5,
    expr='category == "售后政策"',  # 标量过滤
    output_fields=['content', 'category']
)
```

**参数调优**：
```python
'nprobe': 10  # 搜索的聚类中心数量
# - nprobe ↑ → 精度 ↑，速度 ↓
# - 建议：nlist / 10（如 nlist=128 → nprobe=10-20）
```

### 数据持久化

**Docker Volume 映射**：
```yaml
# docker-compose-milvus.yml
volumes:
  - ./volumes/etcd:/etcd         # 元数据
  - ./volumes/minio:/minio       # 向量数据
  - ./volumes/milvus:/var/lib/milvus  # 日志
```

**备份策略**：
```bash
# 停止服务
docker compose -f docker-compose-milvus.yml down

# 备份数据
tar -czf milvus-backup-$(date +%Y%m%d).tar.gz volumes/

# 恢复数据
tar -xzf milvus-backup-YYYYMMDD.tar.gz

# 启动服务
docker compose -f docker-compose-milvus.yml up -d
```

### 监控和维护

**健康检查**：
```bash
# HTTP 健康检查
curl http://localhost:9091/healthz
# 输出: OK

# 查看 Collection 统计
curl -X GET 'http://localhost:9091/api/v1/collection/statistics' \
  -H 'Content-Type: application/json' \
  -d '{"collection_name": "knowledge_base"}'
```

**常用运维命令**：
```python
from pymilvus import utility

# 查看所有 Collection
collections = utility.list_collections()

# 获取 Collection 信息
stats = collection.num_entities  # 实体数量
is_loaded = utility.load_state(collection_name)  # 加载状态

# 释放内存（不删除数据）
collection.release()

# 重新加载
collection.load()

# 删除 Collection
utility.drop_collection(collection_name)
```

### 迁移经验总结

**从 ChromaDB 到 Milvus**：

| 步骤 | ChromaDB | Milvus | 说明 |
|------|----------|--------|------|
| 1. 连接 | `client = chromadb.Client()` | `connections.connect()` | Milvus 需要先连接 |
| 2. Collection | `collection = client.get_or_create_collection()` | `Collection(name, schema)` | Milvus 需要定义 Schema |
| 3. 插入 | `collection.add()` | `collection.insert()` | API 相似 |
| 4. 检索 | `collection.query()` | `collection.search()` | Milvus 更灵活 |
| 5. 删除 | `collection.delete(ids=[...])` | `collection.delete(expr="...")` | Milvus 用表达式 |

**核心变化**：
- ✅ Schema 定义更严格（类型、长度）
- ✅ 需要显式创建索引
- ✅ 需要 load() 到内存
- ✅ 检索 API 更强大（混合查询）

---

## RAG实现原理

### 什么是RAG？

**RAG** (Retrieval-Augmented Generation) = **检索增强生成**

传统对话 vs RAG对话：

```
传统对话:
用户问题 → 大模型 → 回答（可能不准确）

RAG对话:
用户问题 → 检索知识库 → 构建增强提示词 → 大模型 → 回答（更准确）
```

### RAG工作流程

**完整流程**：`backend/src/services/rag_service.py`

```python
async def chat(self, request: ChatRequest) -> ChatResponse:
    """
    步骤1: 向量检索
    - 将用户问题转换为向量
    - 在知识库中检索Top-K相似内容
    """
    search_results = await knowledge_service.search_knowledge(
        query=request.question,
        top_k=3  # 检索最相似的3条
    )
    
    # 检索结果示例:
    # [
    #   {"content": "7天退货政策", "score": 0.95},
    #   {"content": "退货流程说明", "score": 0.87}
    # ]
    
    """
    步骤2: 构建知识库上下文
    """
    knowledge_context = "\n\n".join([
        f'[知识{i+1}] (相似度: {result.score:.2f})\n{result.content}'
        for i, result in enumerate(search_results)
    ])
    
    # 输出:
    # [知识1] (相似度: 0.95)
    # 我们支持7天无理由退货政策...
    #
    # [知识2] (相似度: 0.87)
    # 退货流程：1.联系客服...
    
    """
    步骤3: 填充提示词模板
    """
    full_prompt = PROMPT_TEMPLATE.format(
        knowledge_context=knowledge_context,
        user_question=request.question,
        history_context=history_context
    )
    
    """
    步骤4: 调用大模型
    """
    answer = await aliyun_service.chat([
        Message(role='user', content=full_prompt)
    ])
    
    """
    步骤5: 评估置信度
    """
    confidence = self._evaluate_confidence(
        answer=answer,
        knowledge_found=bool(search_results)
    )
    # 有相关知识 → 高置信度
    # 答案包含不确定词 → 中置信度
    # 无相关知识 → 低置信度
    
    """
    步骤6: 返回结构化结果
    """
    return ChatResponse(
        answer=answer,
        confidence=confidence,
        knowledge_sources=[r.content[:100] for r in search_results],
        llm_model='qwen-max',
        has_image=False
    )
```

### 提示词工程

**提示词模板**：`backend/src/services/rag_service.py`

```python
PROMPT_TEMPLATE = """你是一位资深的抗衰老领域专家。请严格遵守以下规则：

【角色定位】
- 你是一位在抗衰老、健康管理和长寿科学领域有多年研究和实践经验的专家
- 你精通细胞生物学、营养学、运动科学、再生医学等与抗衰老相关的专业知识
- 你的回答要基于科学证据和最新研究成果，专业、严谨、可信
- 你可以提供个性化的抗衰老建议，但要明确指出这不是医疗诊断，建议咨询专业医生

【知识库参考】
{knowledge_context}

【回答要求】
1. **必须优先基于【知识库参考】中的科学文献和专业资料回答**
2. 引用知识库内容时，要说明研究来源或科学依据
3. 如果知识库中没有相关信息，可以基于专业知识回答，但要明确说明"这是基于通用的抗衰老科学知识"
4. 回答要兼顾专业性和易理解性，适当使用类比和实例
5. 涉及具体的营养补充剂、药物或医疗方案时，务必提醒用户咨询专业医生
6. 如果用户问题不够具体，引导用户提供更多信息（如年龄、健康状况、生活方式等）

【用户问题】
{user_question}

【历史对话】
{history_context}

请以专家的角度回答用户问题，提供科学、实用的抗衰老建议。
"""
```

**实际填充示例**：

```
你是一位资深的抗衰老领域专家。请严格遵守以下规则：

【角色定位】
- 你是一位在抗衰老、健康管理和长寿科学领域有多年研究和实践经验的专家
- 你精通细胞生物学、营养学、运动科学、再生医学等与抗衰老相关的专业知识
- 你的回答要基于科学证据和最新研究成果，专业、严谨、可信

【知识库参考】
[知识1] (相似度: 0.95)
NAD+（烟酰胺腺嘌呤二核苷酸）是细胞能量代谢的关键辅酶，随年龄增长而下降。
研究表明，补充NAD+前体如NMN（烟酰胺单核苷酸）可以提升细胞NAD+水平，
改善线粒体功能，延缓衰老相关的代谢退化。

[知识2] (相似度: 0.87)
临床研究发现，每日补充250-500mg NMN持续8-12周，可显著改善中老年人群的
代谢指标、认知功能和体能表现。但需在医生指导下使用，避免与某些药物相互作用。

【回答要求】
1. **必须优先基于【知识库参考】中的科学文献和专业资料回答**
2. 引用知识库内容时，要说明研究来源或科学依据
3. 涉及具体的营养补充剂、药物或医疗方案时，务必提醒用户咨询专业医生

【用户问题】
NMN 对抗衰老有什么作用？应该如何补充？

【历史对话】
这是首次对话。

请以专家的角度回答用户问题，提供科学、实用的抗衰老建议。
```

**大模型回答**：
```
根据现有的科学研究，NMN（烟酰胺单核苷酸）确实在抗衰老方面展现出积极作用：

**作用机制：**
NMN 是 NAD+ 的前体物质。NAD+ 是细胞能量代谢的核心辅酶，但会随年龄增长而下降。
补充 NMN 可以提升细胞内 NAD+ 水平，从而：
1. 改善线粒体功能，增强细胞能量产生
2. 激活长寿蛋白（Sirtuins），促进DNA修复
3. 延缓衰老相关的代谢退化

**补充建议：**
临床研究建议的剂量为每日 250-500mg，持续 8-12 周可见效果。可能改善：
- 代谢指标（血糖、血脂）
- 认知功能和记忆力
- 体能和运动表现

**重要提醒：**
1. ⚠️ 请在医生或营养师指导下使用，尤其是有慢性疾病或正在服药者
2. 注意产品纯度和来源，选择经过第三方检测的品牌
3. NMN 不能替代健康的生活方式（饮食、运动、睡眠）

如需个性化方案，建议咨询专业的抗衰老医学机构。
```

### 置信度评估

```python
def _evaluate_confidence(self, answer, knowledge_found):
    """
    评估规则：
    1. 没有找到相关知识 → 低置信度
    2. 答案过短（<20字符）→ 低置信度
    3. 包含不确定词汇 → 中置信度
       ["可能", "也许", "大概", "不确定", "不太清楚"]
    4. 其他情况 → 高置信度
    """
    if not knowledge_found:
        return '低'
    
    if len(answer) < 20:
        return '低'
    
    uncertain_words = ['可能', '也许', '大概', '不确定']
    if any(word in answer for word in uncertain_words):
        return '中'
    
    return '高'
```

---

## 启动方式

### 一键启动（推荐）⭐

使用统一启动脚本，自动启动 Milvus + 后端 + 前端：

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1
bash 启动服务.sh
```

**脚本功能**：
- ✅ 检查并启动 Milvus Docker 容器
- ✅ 等待 Milvus 就绪
- ✅ 启动后端服务（自动激活虚拟环境）
- ✅ 启动前端服务
- ✅ 验证所有服务状态
- ✅ 显示访问地址

**停止所有服务**：
```bash
bash 停止服务.sh
```

---

### 分别启动

#### 1. 启动 Milvus

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1
docker compose -f docker-compose-milvus.yml up -d
```

**验证**：
```bash
# 检查容器状态
docker compose -f docker-compose-milvus.yml ps

# 健康检查
curl http://localhost:9091/healthz
# 输出: OK
```

#### 2. 启动后端

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/backend
source venv/bin/activate
python -m uvicorn src.main:app --host 0.0.0.0 --port 8001 --reload
```

**访问**：
- API文档: http://localhost:8001/docs
- 健康检查: http://localhost:8001/health

#### 3. 启动前端

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/frontend
npm start
```

**访问**: http://localhost:3000

---

### 服务端口

| 服务 | 端口 | 说明 |
|------|------|------|
| 前端 | 3000 | React 开发服务器 |
| 后端 API | 8001 | FastAPI 应用 |
| Milvus | 19530 | gRPC 接口 |
| Milvus HTTP | 9091 | HTTP 管理接口 |
| MinIO | 9000 | 对象存储 |
| MinIO Console | 9001 | 管理控制台 |

---

## API接口说明

### 1. RAG对话接口

**接口**: `POST /api/v1/chat/`

**请求示例**：
```json
{
  "question": "如何申请退货？",
  "use_knowledge_base": true,
  "history": [
    {"role": "user", "content": "你好"},
    {"role": "assistant", "content": "您好"}
  ]
}
```

**响应示例**：
```json
{
  "answer": "您可以在收货后7天内申请退货...",
  "confidence": "高",
  "knowledge_sources": [
    "我们支持7天无理由退货...",
    "退货流程：1.联系客服..."
  ],
  "llm_model": "qwen-max",
  "has_image": false
}
```

### 2. 图文对话接口

**接口**: `POST /api/v1/chat/with-image`

**请求示例**：
```bash
curl -X POST "http://localhost:8000/api/v1/chat/with-image" \
  -F "question=这是什么产品？" \
  -F "image=@product.jpg"
```

### 3. 添加知识接口

**接口**: `POST /api/v1/knowledge/add`

**请求示例**：
```json
{
  "content": "我们支持7天无理由退货",
  "category": "售后政策",
  "metadata": {
    "source": "官网",
    "version": "1.0"
  }
}
```

**响应示例**：
```json
{
  "success": true,
  "message": "知识条目添加成功",
  "doc_id": "a1b2c3d4e5f6"
}
```

### 4. 检索知识接口

**接口**: `GET /api/v1/knowledge/search?query=退货&top_k=3`

**响应示例**：
```json
[
  {
    "content": "我们支持7天无理由退货",
    "category": "售后政策",
    "score": 0.95,
    "metadata": {"source": "官网"}
  }
]
```

---

## 性能指标

### 响应时间

#### ChromaDB vs Milvus 性能对比

| 指标 | ChromaDB | Milvus | 提升 |
|------|----------|--------|------|
| 向量检索 | ~100ms | ~30-50ms | ⬆️ 2-3倍 |
| 插入速度 | 中等 | 快 | ⬆️ 2-3倍 |
| 数据量支持 | < 100万 | > 10亿 | ⬆️ 100倍+ |

**当前性能**（Milvus）：
- **向量检索**: 30-50ms
- **文本向量化**: ~50ms/句
- **大模型调用**: 3-5秒
- **总响应时间**: 3-6秒

### Token使用

**典型对话**：
- 输入: 150-200 tokens
- 输出: 50-100 tokens
- 总计: 200-300 tokens/次

### 存储需求

**Milvus 存储**：
- **向量数据**: ~2KB/条知识
- **1000条知识**: ~2MB（向量）+ ~500KB（元数据）
- **向量模型**: 471MB（一次性下载）
- **Milvus Docker 镜像**: ~1GB
- **运行时内存**: 4-8GB（推荐）

---

## 项目文件结构

```
demo-v1/
├── 启动服务.sh                     # ⭐ 一键启动脚本
├── 停止服务.sh                     # ⭐ 一键停止脚本
├── docker-compose-milvus.yml       # Milvus Docker 配置
├── .gitignore                      # Git 忽略配置
│
├── backend/                        # 后端服务
│   ├── requirements.txt            # Python依赖（含 pymilvus）
│   ├── env_template.txt            # 环境配置（含API Key）
│   ├── example_knowledge.json      # 示例知识数据
│   ├── load_example_knowledge.py   # 数据加载脚本
│   ├── test_milvus_integration.py  # Milvus 集成测试
│   │
│   └── src/                        # 源代码
│       ├── main.py                 # FastAPI入口
│       ├── api/routers/            # API路由
│       │   ├── chat.py             # 对话接口
│       │   └── knowledge.py        # 知识库接口
│       ├── services/               # 服务层
│       │   ├── rag_service.py      # RAG核心逻辑
│       │   ├── aliyun_service.py   # 大模型调用
│       │   └── knowledge_service.py # ⭐ Milvus 知识库管理
│       ├── models/schemas/         # 数据模型
│       ├── utils/                  # 工具函数
│       └── config/                 # 配置管理（含 Milvus 配置）
│
├── frontend/                       # 前端应用
│   ├── package.json                # Node依赖
│   └── src/
│       ├── App.tsx                 # 主应用
│       ├── components/             # React组件
│       ├── services/api.ts         # API调用（端口 8001）
│       └── styles/                 # 样式文件
│
├── volumes/                        # Docker 数据卷（.gitignore）
│   ├── etcd/                       # Milvus 元数据
│   ├── minio/                      # Milvus 对象存储
│   └── milvus/                     # Milvus 数据文件
│
├── README.md                       # 项目说明
├── 项目详细说明.md                 # ⭐ 本文档
├── Milvus迁移完成报告.md           # Milvus 迁移文档
└── 多模态功能实施方案.md           # 多模态扩展规划
```

---

## 总结

### 核心技术亮点

1. **RAG架构**: 检索增强生成，回答更准确
2. **Milvus 向量数据库**: 企业级、高性能、可扩展
3. **向量检索**: 语义相似度匹配，而非关键词
4. **提示词工程**: 结构化模板，确保输出一致
5. **多模态支持**: 文本+图片理解
6. **企业级代码**: 完整类型提示、错误处理、日志
7. **Docker 部署**: 容器化、易迁移、易扩展

### 使用场景

- 🧬 **抗衰老咨询**：NMN、NAD+、线粒体健康等专业问题
- 💊 **营养补充剂指导**：科学依据的补充建议
- 🏃 **运动与健康管理**：个性化的运动和生活方式建议
- 🔬 **最新研究解读**：解读抗衰老领域的科学文献
- 📊 **健康指标分析**：上传检查报告，获取专业解读
- 🍎 **饮食与长寿**：基于科学的饮食建议

### Milvus 优势总结

| 特性 | 说明 | 价值 |
|------|------|------|
| **高性能** | 毫秒级检索，支持 10 亿+向量 | 适合大规模应用 |
| **可扩展** | 支持分布式部署 | 易于横向扩展 |
| **多模态** | 统一存储文本、图片、视频向量 | 为未来扩展做好准备 |
| **企业级** | 高可用、数据持久化、ACID | 生产环境可靠 |
| **开源** | Apache 2.0 许可 | 无供应商锁定 |

### 技术演进路线图

**当前版本（v1.0）**：
- ✅ Milvus 向量数据库
- ✅ 文本知识库
- ✅ RAG 对话
- ✅ 基础多模态（图文输入）

**规划中（v2.0）**：
- 📋 图片知识库（CLIP 编码）
- 📋 PDF 文档解析
- 📋 以图搜图
- 📋 混合检索（文本+图片）
- 📋 更多大模型支持

**未来展望（v3.0）**：
- 🔮 视频理解
- 🔮 音频转录
- 🔮 实时流式输出
- 🔮 多轮对话优化
- 🔮 知识图谱集成

---

**文档版本**: 1.1 (更新 Milvus 迁移)  
**更新时间**: 2024-10-23  
**技术栈**: Python 3.11 + FastAPI + Milvus 2.4 + React  
**部署方式**: Docker Compose (本地) / Kubernetes (生产)  

**相关文档**：
- 📄 [Milvus迁移完成报告.md](./Milvus迁移完成报告.md) - 迁移过程和测试结果
- 📄 [多模态功能实施方案.md](./多模态功能实施方案.md) - 多模态扩展详细规划
- 📄 [README.md](./README.md) - 项目快速开始

