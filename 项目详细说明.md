# RAG智能对话系统 - 详细技术说明

## 📋 目录

1. [项目概述](#项目概述)
2. [核心功能](#核心功能)
3. [技术架构](#技术架构)
4. [大模型调用详解](#大模型调用详解)
5. [数据库设计](#数据库设计)
6. [RAG实现原理](#rag实现原理)
7. [启动方式](#启动方式)
8. [API接口说明](#api接口说明)

---

## 项目概述

这是一个基于**阿里云通义千问大模型**的RAG（检索增强生成）智能对话系统。

### 核心特点

- ✅ 支持自定义知识库，实现领域专业问答
- ✅ 支持文本和图片多模态输入
- ✅ 使用向量数据库实现语义检索
- ✅ 结构化提示词工程，确保输出格式一致
- ✅ 企业级Python代码规范
- ✅ 移动端响应式前端界面

---

## 核心功能

### 1. 知识库管理

**功能说明**：
- 动态添加、删除、查询知识条目
- 自动文本分块和向量化
- 支持分类管理和元数据标注
- 批量导入知识

**技术实现**：
- 使用 ChromaDB 作为向量数据库
- Sentence-Transformers 进行文本向量化
- 支持语义相似度检索（Top-K）

### 2. RAG智能问答

**功能说明**：
- 基于知识库的上下文增强回答
- 自动检索相关知识并构建提示词
- 返回答案置信度和知识来源
- 支持历史对话上下文

**技术实现**：
- 向量检索 + 大模型生成
- 结构化提示词模板
- 置信度自动评估

### 3. 多模态对话

**功能说明**：
- 支持图片上传和识别
- 图文混合输入
- 自动图片压缩和Base64编码

**技术实现**：
- 使用阿里云通义千问-VL多模态模型
- PIL图片处理
- Base64编码传输

---

## 技术架构

### 整体架构图

```
┌─────────────────────────────────────────────────────────┐
│                    前端 (React)                          │
│  - 聊天界面  - 知识库管理  - 图片上传  - 历史记录       │
└───────────────────────┬─────────────────────────────────┘
                        │ HTTP REST API
                        ▼
┌─────────────────────────────────────────────────────────┐
│                FastAPI 路由层                            │
│  /api/v1/chat/          - RAG对话接口                   │
│  /api/v1/knowledge/     - 知识库管理接口                │
└───────────────────────┬─────────────────────────────────┘
                        │
                        ▼
┌─────────────────────────────────────────────────────────┐
│                   服务层 (Services)                      │
│  ┌───────────────────────────────────────────────┐      │
│  │  RAGService (核心编排)                         │      │
│  │  - 接收用户问题                                │      │
│  │  - 调用知识检索                                │      │
│  │  - 构建提示词                                  │      │
│  │  - 调用大模型                                  │      │
│  │  - 评估置信度                                  │      │
│  └──────────┬──────────────────┬──────────────────┘      │
│            │                  │                         │
│  ┌─────────▼─────────┐  ┌────▼───────────────┐        │
│  │ KnowledgeService  │  │  AliyunService     │        │
│  │ (知识库管理)       │  │  (大模型调用)       │        │
│  │                   │  │                    │        │
│  │ - 文本向量化       │  │ - API密钥管理       │        │
│  │ - 向量检索         │  │ - 重试机制         │        │
│  │ - CRUD操作        │  │ - 异步调用         │        │
│  └─────────┬─────────┘  └────────────────────┘        │
└────────────┼──────────────────────────────────────────┘
             │
             ▼
┌─────────────────────────────────────────────────────────┐
│                   数据层                                 │
│  ┌─────────────────┐  ┌──────────────────────────┐     │
│  │   ChromaDB      │  │  阿里云通义千问 API       │     │
│  │  (向量数据库)    │  │  - qwen-max (文本)       │     │
│  │                 │  │  - qwen-vl-max (图文)    │     │
│  │  持久化路径:     │  │                          │     │
│  │  ./data/chroma  │  │  API Key: sk-8b6d...     │     │
│  └─────────────────┘  └──────────────────────────┘     │
└─────────────────────────────────────────────────────────┘
```

### 技术栈

#### 后端
| 技术 | 版本 | 用途 |
|------|------|------|
| Python | 3.11.7 | 编程语言 |
| FastAPI | 0.109.0 | Web框架 |
| Uvicorn | 0.27.0 | ASGI服务器 |
| ChromaDB | 0.4.22 | 向量数据库 |
| Sentence-Transformers | 2.3.1 | 文本向量化 |
| DashScope | 1.14.1 | 阿里云SDK |
| Pydantic | 2.5.3 | 数据验证 |
| NumPy | 1.26.4 | 数值计算 |

#### 前端
| 技术 | 版本 | 用途 |
|------|------|------|
| React | 18.2.0 | UI框架 |
| TypeScript | 4.9.5 | 类型安全 |
| Axios | 1.6.5 | HTTP客户端 |

---

## 大模型调用详解

### 1. 使用的模型

#### 文本对话模型
- **模型名称**: `qwen-max`
- **供应商**: 阿里云通义千问
- **能力**: 纯文本理解和生成
- **上下文长度**: 支持较长上下文
- **用途**: RAG对话、知识问答

#### 多模态模型
- **模型名称**: `qwen-vl-max`  
- **供应商**: 阿里云通义千问
- **能力**: 图文混合理解
- **用途**: 图片识别、图文问答

### 2. API调用配置

**配置文件**: `backend/env_template.txt`

```bash
# 阿里云API密钥
DASHSCOPE_API_KEY=sk-8b6db5929e244a159deb8e77b08bcf5b

# 模型配置
DEFAULT_LLM_MODEL=qwen-max        # 默认文本模型
DEFAULT_VL_MODEL=qwen-vl-max      # 默认多模态模型
MAX_TOKENS=2000                   # 最大生成token数
TEMPERATURE=0.7                   # 温度参数（创造性）
```

### 3. 调用流程

#### 纯文本对话流程

```python
# 文件: backend/src/services/aliyun_service.py

async def chat(self, messages, model=None):
    """
    1. 格式化消息
    messages = [
        {'role': 'user', 'content': '用户问题'}
    ]
    
    2. 调用API
    response = Generation.call(
        model='qwen-max',           # 模型名称
        messages=messages,          # 对话消息
        temperature=0.7,            # 温度参数
        max_tokens=2000,           # 最大token
        result_format='message'     # 返回格式
    )
    
    3. 解析响应
    answer = response.output.choices[0].message.content
    
    4. 返回结果
    return answer
    """
```

#### 图文对话流程

```python
# 文件: backend/src/services/aliyun_service.py

async def chat_with_image(self, text, image_url=None, image_base64=None):
    """
    1. 构建多模态内容
    content = [
        {'text': '用户文本'},
        {'image': 'data:image/jpeg;base64,xxx'}  # Base64图片
    ]
    
    2. 构建消息
    messages = [
        {
            'role': 'user',
            'content': content
        }
    ]
    
    3. 调用多模态API
    response = MultiModalConversation.call(
        model='qwen-vl-max',    # 多模态模型
        messages=messages
    )
    
    4. 提取回答
    answer = response.output.choices[0].message.content[0]['text']
    
    5. 返回结果
    return answer
    """
```

### 4. 重试机制

使用 `tenacity` 库实现自动重试：

```python
@retry(
    stop=stop_after_attempt(3),          # 最多重试3次
    wait=wait_exponential(                # 指数退避
        multiplier=1, 
        min=2,                            # 最小等待2秒
        max=10                            # 最大等待10秒
    ),
    retry=retry_if_exception_type(Exception),
    reraise=True                          # 重新抛出异常
)
async def chat(self, messages):
    # API调用逻辑
    pass
```

**重试策略**：
- 第1次失败：等待2秒后重试
- 第2次失败：等待4秒后重试
- 第3次失败：等待8秒后重试
- 3次都失败：抛出异常

### 5. Token使用监控

每次API调用都会记录token使用情况：

```python
logger.info(
    f'模型调用成功 - '
    f'模型: {model}, '
    f'输入token: {response.usage.input_tokens}, '
    f'输出token: {response.usage.output_tokens}'
)
```

**示例日志**：
```
模型调用成功 - 模型: qwen-max, 输入token: 169, 输出token: 59
```

---

## 数据库设计

### 1. 向量数据库 (ChromaDB)

**存储位置**: `backend/data/chroma_db`

**数据结构**：

```python
{
    "id": "doc_hash_chunk_0",              # 文档ID_分块索引
    "embedding": [0.1, 0.2, ..., 0.9],     # 384维向量
    "document": "知识文本内容",             # 原始文本
    "metadata": {                          # 元数据
        "category": "售后政策",            # 分类
        "created_at": "2024-01-01T00:00:00",  # 创建时间
        "chunk_count": 3,                  # 总分块数
        "source": "官网"                   # 来源
    }
}
```

### 2. 向量化模型

**模型名称**: `paraphrase-multilingual-MiniLM-L12-v2`

**模型参数**：
- **维度**: 384
- **支持语言**: 50+（包括中文、英文等）
- **模型大小**: 471MB
- **速度**: ~5ms/句
- **提供商**: Sentence-Transformers

**工作原理**：
```python
# 文本 -> 向量
text = "我们支持7天无理由退货"
embedding = model.encode(text)  
# 输出: [0.123, -0.456, 0.789, ...] (384维)
```

### 3. 文本分块策略

**为什么需要分块**：
- 单个文本过长会影响检索精度
- 大模型有上下文长度限制

**分块参数**：
```python
CHUNK_SIZE = 500        # 每块500字符
CHUNK_OVERLAP = 50      # 块之间重叠50字符
```

**分块示例**：
```
原文: "我们支持7天无理由退货。退货时需要保持商品完好。退货流程：1.联系客服..."

分块后:
chunk_0: "我们支持7天无理由退货。退货时需要保持商品完好。退货流程：1.联系客服..."
chunk_1: "...退货流程：1.联系客服 2.填写退货单 3.寄回商品..."
         ^重叠部分^
```

### 4. 相似度计算

**算法**: L2距离（欧氏距离）

```python
# 计算查询向量和文档向量的距离
distance = ||query_embedding - doc_embedding||

# 转换为相似度分数 (0-1)
score = max(0, 1 - distance)
```

**检索过程**：
```python
# 1. 用户问题向量化
query = "如何退货？"
query_embedding = model.encode(query)  # [0.1, 0.3, ...]

# 2. 在向量库中搜索最相似的Top-K
results = collection.query(
    query_embeddings=[query_embedding],
    n_results=3  # 返回最相似的3条
)

# 3. 返回结果
[
    {"content": "退货政策...", "score": 0.95},
    {"content": "退货流程...", "score": 0.87},
    {"content": "退货条件...", "score": 0.76}
]
```

---

## RAG实现原理

### 什么是RAG？

**RAG** (Retrieval-Augmented Generation) = **检索增强生成**

传统对话 vs RAG对话：

```
传统对话:
用户问题 → 大模型 → 回答（可能不准确）

RAG对话:
用户问题 → 检索知识库 → 构建增强提示词 → 大模型 → 回答（更准确）
```

### RAG工作流程

**完整流程**：`backend/src/services/rag_service.py`

```python
async def chat(self, request: ChatRequest) -> ChatResponse:
    """
    步骤1: 向量检索
    - 将用户问题转换为向量
    - 在知识库中检索Top-K相似内容
    """
    search_results = await knowledge_service.search_knowledge(
        query=request.question,
        top_k=3  # 检索最相似的3条
    )
    
    # 检索结果示例:
    # [
    #   {"content": "7天退货政策", "score": 0.95},
    #   {"content": "退货流程说明", "score": 0.87}
    # ]
    
    """
    步骤2: 构建知识库上下文
    """
    knowledge_context = "\n\n".join([
        f'[知识{i+1}] (相似度: {result.score:.2f})\n{result.content}'
        for i, result in enumerate(search_results)
    ])
    
    # 输出:
    # [知识1] (相似度: 0.95)
    # 我们支持7天无理由退货政策...
    #
    # [知识2] (相似度: 0.87)
    # 退货流程：1.联系客服...
    
    """
    步骤3: 填充提示词模板
    """
    full_prompt = PROMPT_TEMPLATE.format(
        knowledge_context=knowledge_context,
        user_question=request.question,
        history_context=history_context
    )
    
    """
    步骤4: 调用大模型
    """
    answer = await aliyun_service.chat([
        Message(role='user', content=full_prompt)
    ])
    
    """
    步骤5: 评估置信度
    """
    confidence = self._evaluate_confidence(
        answer=answer,
        knowledge_found=bool(search_results)
    )
    # 有相关知识 → 高置信度
    # 答案包含不确定词 → 中置信度
    # 无相关知识 → 低置信度
    
    """
    步骤6: 返回结构化结果
    """
    return ChatResponse(
        answer=answer,
        confidence=confidence,
        knowledge_sources=[r.content[:100] for r in search_results],
        llm_model='qwen-max',
        has_image=False
    )
```

### 提示词工程

**提示词模板**：`backend/src/services/rag_service.py`

```python
PROMPT_TEMPLATE = """你是一个专业、友好的智能助手。请严格遵守以下规则：

【角色定位】
- 你是企业的官方客服助手
- 回答要准确、专业、有礼貌
- 如果不确定，诚实告知用户

【知识库参考】
{knowledge_context}

【回答要求】
1. **必须优先基于【知识库参考】中的内容回答**
2. 如果知识库中没有相关信息，可以基于常识回答，但要说明"这不是官方信息"
3. 回答要简洁明了，避免冗长
4. 如果用户问题不清楚，引导用户补充信息

【用户问题】
{user_question}

【历史对话】
{history_context}

请直接回答用户问题，不要重复上述规则。
"""
```

**实际填充示例**：

```
你是一个专业、友好的智能助手。请严格遵守以下规则：

【角色定位】
- 你是企业的官方客服助手
- 回答要准确、专业、有礼貌

【知识库参考】
[知识1] (相似度: 0.95)
我们支持7天无理由退货。收到商品后7天内，如对产品不满意，可以申请退货。

[知识2] (相似度: 0.87)
退货流程：1.在订单页面点击申请退货 2.选择退货原因 3.寄回商品

【回答要求】
1. **必须优先基于【知识库参考】中的内容回答**
2. 回答要简洁明了，避免冗长

【用户问题】
如何申请退货？

【历史对话】
这是首次对话。

请直接回答用户问题，不要重复上述规则。
```

**大模型回答**：
```
您可以在收货后7天内申请退货。具体流程：
1. 在订单页面点击"申请退货"
2. 选择退货原因并提交
3. 按照系统提示寄回商品

如需帮助，欢迎随时联系我们的客服。
```

### 置信度评估

```python
def _evaluate_confidence(self, answer, knowledge_found):
    """
    评估规则：
    1. 没有找到相关知识 → 低置信度
    2. 答案过短（<20字符）→ 低置信度
    3. 包含不确定词汇 → 中置信度
       ["可能", "也许", "大概", "不确定", "不太清楚"]
    4. 其他情况 → 高置信度
    """
    if not knowledge_found:
        return '低'
    
    if len(answer) < 20:
        return '低'
    
    uncertain_words = ['可能', '也许', '大概', '不确定']
    if any(word in answer for word in uncertain_words):
        return '中'
    
    return '高'
```

---

## 启动方式

### 后端启动

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/backend
./start.sh
```

**或手动启动**：
```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/backend
source venv/bin/activate
python -m uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

**访问**：
- API文档: http://localhost:8000/docs
- 健康检查: http://localhost:8000/health

### 前端启动

```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/frontend
./start.sh
```

**或手动启动**：
```bash
cd /Users/liguangyuan/Documents/GitHub/demo-v1/frontend
npm install  # 首次需要
npm start
```

**访问**: http://localhost:3000

---

## API接口说明

### 1. RAG对话接口

**接口**: `POST /api/v1/chat/`

**请求示例**：
```json
{
  "question": "如何申请退货？",
  "use_knowledge_base": true,
  "history": [
    {"role": "user", "content": "你好"},
    {"role": "assistant", "content": "您好"}
  ]
}
```

**响应示例**：
```json
{
  "answer": "您可以在收货后7天内申请退货...",
  "confidence": "高",
  "knowledge_sources": [
    "我们支持7天无理由退货...",
    "退货流程：1.联系客服..."
  ],
  "llm_model": "qwen-max",
  "has_image": false
}
```

### 2. 图文对话接口

**接口**: `POST /api/v1/chat/with-image`

**请求示例**：
```bash
curl -X POST "http://localhost:8000/api/v1/chat/with-image" \
  -F "question=这是什么产品？" \
  -F "image=@product.jpg"
```

### 3. 添加知识接口

**接口**: `POST /api/v1/knowledge/add`

**请求示例**：
```json
{
  "content": "我们支持7天无理由退货",
  "category": "售后政策",
  "metadata": {
    "source": "官网",
    "version": "1.0"
  }
}
```

**响应示例**：
```json
{
  "success": true,
  "message": "知识条目添加成功",
  "doc_id": "a1b2c3d4e5f6"
}
```

### 4. 检索知识接口

**接口**: `GET /api/v1/knowledge/search?query=退货&top_k=3`

**响应示例**：
```json
[
  {
    "content": "我们支持7天无理由退货",
    "category": "售后政策",
    "score": 0.95,
    "metadata": {"source": "官网"}
  }
]
```

---

## 性能指标

### 响应时间

- **向量检索**: ~100ms
- **文本向量化**: ~50ms/句
- **大模型调用**: 3-5秒
- **总响应时间**: 3-6秒

### Token使用

**典型对话**：
- 输入: 150-200 tokens
- 输出: 50-100 tokens
- 总计: 200-300 tokens/次

### 存储需求

- **向量数据库**: ~2KB/条知识
- **1000条知识**: ~2MB
- **向量模型**: 471MB（一次性下载）

---

## 项目文件结构

```
demo-v1/
├── backend/                        # 后端服务
│   ├── start.sh                    # ⭐ 启动脚本
│   ├── requirements.txt            # Python依赖
│   ├── env_template.txt            # 环境配置（含API Key）
│   ├── example_knowledge.json      # 示例知识数据
│   ├── load_example_knowledge.py   # 数据加载脚本
│   │
│   └── src/                        # 源代码
│       ├── main.py                 # FastAPI入口
│       ├── api/routers/            # API路由
│       │   ├── chat.py             # 对话接口
│       │   └── knowledge.py        # 知识库接口
│       ├── services/               # 服务层
│       │   ├── rag_service.py      # RAG核心逻辑
│       │   ├── aliyun_service.py   # 大模型调用
│       │   └── knowledge_service.py # 知识库管理
│       ├── models/schemas/         # 数据模型
│       ├── utils/                  # 工具函数
│       └── config/                 # 配置管理
│
├── frontend/                       # 前端应用
│   ├── start.sh                    # ⭐ 启动脚本
│   ├── package.json                # Node依赖
│   └── src/
│       ├── App.tsx                 # 主应用
│       ├── components/             # React组件
│       ├── services/api.ts         # API调用
│       └── styles/                 # 样式文件
│
├── README.md                       # 项目说明
└── 项目详细说明.md                 # ⭐ 本文档
```

---

## 总结

### 核心技术亮点

1. **RAG架构**: 检索增强生成，回答更准确
2. **向量检索**: 语义相似度匹配，而非关键词
3. **提示词工程**: 结构化模板，确保输出一致
4. **多模态支持**: 文本+图片理解
5. **企业级代码**: 完整类型提示、错误处理、日志

### 使用场景

- 🏢 企业客服系统
- 📚 知识库问答
- 🎓 教育辅助
- 💼 业务咨询
- 🔍 文档检索

---

**文档版本**: 1.0  
**更新时间**: 2024-10-23  
**联系方式**: 项目开发团队

