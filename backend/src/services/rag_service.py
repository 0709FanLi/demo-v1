"""RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æœåŠ¡.

æ•´åˆçŸ¥è¯†åº“æ£€ç´¢å’Œå¤§æ¨¡å‹æ¨ç†ã€‚
éµå®ˆä¼ä¸šçº§è§„èŒƒï¼š
- ç»“æ„åŒ–æç¤ºè¯æ¨¡æ¿
- å¯é…ç½®çš„æ£€ç´¢ç­–ç•¥
- å®Œæ•´çš„é”™è¯¯å¤„ç†
"""

from typing import Optional, List, Literal

from ..config import settings
from ..models.schemas import ChatRequest, ChatResponse, Message
from ..utils import logger
from .knowledge_service import KnowledgeService
from .aliyun_service import AliyunService


# ç»“æ„åŒ–æç¤ºè¯æ¨¡æ¿
PROMPT_TEMPLATE = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æŠ—è¡°è€é¢†åŸŸä¸“å®¶ã€‚è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

ã€è§’è‰²å®šä½ã€‘
- ä½ æ˜¯ä¸€ä½åœ¨æŠ—è¡°è€ã€å¥åº·ç®¡ç†å’Œé•¿å¯¿ç§‘å­¦é¢†åŸŸæœ‰å¤šå¹´ç ”ç©¶å’Œå®è·µç»éªŒçš„ä¸“å®¶
- ä½ ç²¾é€šç»†èƒç”Ÿç‰©å­¦ã€è¥å…»å­¦ã€è¿åŠ¨ç§‘å­¦ã€å†ç”ŸåŒ»å­¦ç­‰ä¸æŠ—è¡°è€ç›¸å…³çš„ä¸“ä¸šçŸ¥è¯†
- ä½ çš„å›ç­”è¦åŸºäºç§‘å­¦è¯æ®å’Œæœ€æ–°ç ”ç©¶æˆæœï¼Œä¸“ä¸šã€ä¸¥è°¨ã€å¯ä¿¡
- ä½ å¯ä»¥æä¾›ä¸ªæ€§åŒ–çš„æŠ—è¡°è€å»ºè®®ï¼Œä½†è¦æ˜ç¡®æŒ‡å‡ºè¿™ä¸æ˜¯åŒ»ç–—è¯Šæ–­ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ

ã€çŸ¥è¯†åº“å‚è€ƒã€‘
{knowledge_context}

ã€å›ç­”è¦æ±‚ã€‘
1. **å¿…é¡»ä¼˜å…ˆåŸºäºã€çŸ¥è¯†åº“å‚è€ƒã€‘ä¸­çš„ç§‘å­¦æ–‡çŒ®å’Œä¸“ä¸šèµ„æ–™å›ç­”**
2. å¼•ç”¨çŸ¥è¯†åº“å†…å®¹æ—¶ï¼Œè¦è¯´æ˜ç ”ç©¶æ¥æºæˆ–ç§‘å­¦ä¾æ®
3. å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¯ä»¥åŸºäºä¸“ä¸šçŸ¥è¯†å›ç­”ï¼Œä½†è¦æ˜ç¡®è¯´æ˜"è¿™æ˜¯åŸºäºé€šç”¨çš„æŠ—è¡°è€ç§‘å­¦çŸ¥è¯†"
4. å›ç­”è¦å…¼é¡¾ä¸“ä¸šæ€§å’Œæ˜“ç†è§£æ€§ï¼Œé€‚å½“ä½¿ç”¨ç±»æ¯”å’Œå®ä¾‹
5. æ¶‰åŠå…·ä½“çš„è¥å…»è¡¥å……å‰‚ã€è¯ç‰©æˆ–åŒ»ç–—æ–¹æ¡ˆæ—¶ï¼ŒåŠ¡å¿…æé†’ç”¨æˆ·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿ
6. å¦‚æœç”¨æˆ·é—®é¢˜ä¸å¤Ÿå…·ä½“ï¼Œå¼•å¯¼ç”¨æˆ·æä¾›æ›´å¤šä¿¡æ¯ï¼ˆå¦‚å¹´é¾„ã€å¥åº·çŠ¶å†µã€ç”Ÿæ´»æ–¹å¼ç­‰ï¼‰

ã€ç”¨æˆ·é—®é¢˜ã€‘
{user_question}

ã€å†å²å¯¹è¯ã€‘
{history_context}

è¯·ä»¥ä¸“å®¶çš„è§’åº¦å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæä¾›ç§‘å­¦ã€å®ç”¨çš„æŠ—è¡°è€å»ºè®®ã€‚
"""


class RAGService:
    """RAGæœåŠ¡ç±».
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ£€ç´¢ç›¸å…³çŸ¥è¯†
    2. æ„å»ºå¢å¼ºæç¤ºè¯
    3. è°ƒç”¨å¤§æ¨¡å‹
    4. è¯„ä¼°å›ç­”è´¨é‡
    """
    
    def __init__(
        self,
        knowledge_service: Optional[KnowledgeService] = None,
        aliyun_service: Optional[AliyunService] = None,
    ):
        """åˆå§‹åŒ–RAGæœåŠ¡.
        
        Args:
            knowledge_service: çŸ¥è¯†åº“æœåŠ¡å®ä¾‹
            aliyun_service: é˜¿é‡Œäº‘æœåŠ¡å®ä¾‹
        """
        self.knowledge_service = knowledge_service or KnowledgeService()
        self.aliyun_service = aliyun_service or AliyunService()
        logger.info('RAGæœåŠ¡åˆå§‹åŒ–å®Œæˆ')
    
    async def chat(
        self,
        request: ChatRequest,
    ) -> ChatResponse:
        """RAGå¯¹è¯ä¸»æ–¹æ³•.
        
        Args:
            request: å¯¹è¯è¯·æ±‚
            
        Returns:
            å¯¹è¯å“åº”
        """
        try:
            # æ­¥éª¤1: æ£€ç´¢çŸ¥è¯†åº“
            knowledge_sources = []
            knowledge_context = 'æš‚æ— ç›¸å…³çŸ¥è¯†åº“ä¿¡æ¯ã€‚'
            max_relevance_score = 0.0
            is_out_of_scope = False
            
            if request.use_knowledge_base:
                search_results = await self.knowledge_service.search_knowledge(
                    query=request.question,
                    top_k=settings.knowledge_top_k,
                )
                
                if search_results:
                    # è·å–æœ€é«˜ç›¸ä¼¼åº¦
                    max_relevance_score = search_results[0].score
                    
                    # åˆ¤æ–­æ˜¯å¦è¶…å‡ºçŸ¥è¯†åº“èŒƒå›´
                    if max_relevance_score < settings.knowledge_relevance_threshold:
                        is_out_of_scope = True
                        logger.info(
                            f'é—®é¢˜è¶…å‡ºçŸ¥è¯†åº“èŒƒå›´ - æœ€é«˜ç›¸ä¼¼åº¦: {max_relevance_score:.2f}, '
                            f'é˜ˆå€¼: {settings.knowledge_relevance_threshold}'
                        )
                    else:
                        knowledge_sources = [
                            f'{result.content[:100]}...' 
                            for result in search_results
                        ]
                        
                        knowledge_context = '\n\n'.join([
                            f'[çŸ¥è¯†{i+1}] (ç›¸ä¼¼åº¦: {result.score:.2f})\n{result.content}'
                            for i, result in enumerate(search_results)
                        ])
                        
                        logger.info(
                            f'æ£€ç´¢åˆ° {len(search_results)} æ¡ç›¸å…³çŸ¥è¯†, '
                            f'æœ€é«˜ç›¸ä¼¼åº¦: {max_relevance_score:.2f}'
                        )
                else:
                    # æ²¡æœ‰æ£€ç´¢ç»“æœï¼Œä¹Ÿè§†ä¸ºè¶…å‡ºèŒƒå›´
                    is_out_of_scope = True
                    logger.info('çŸ¥è¯†åº“æ£€ç´¢æ— ç»“æœï¼Œè§†ä¸ºè¶…å‡ºèŒƒå›´')
            
            # æ­¥éª¤2: å¦‚æœè¶…å‡ºèŒƒå›´ï¼Œç›´æ¥è¿”å›å‹å¥½æç¤º
            if is_out_of_scope:
                out_of_scope_message = self._generate_out_of_scope_message(
                    question=request.question,
                    max_score=max_relevance_score,
                )
                
                return ChatResponse(
                    answer=out_of_scope_message,
                    confidence='ä½',
                    knowledge_sources=[],
                    llm_model='out_of_scope',
                    has_image=False,
                    out_of_scope=True,
                    relevance_score=max_relevance_score,
                )
            
            # æ­¥éª¤3: æ„å»ºå†å²å¯¹è¯ä¸Šä¸‹æ–‡
            history_context = 'è¿™æ˜¯é¦–æ¬¡å¯¹è¯ã€‚'
            if request.history:
                history_parts = []
                for msg in request.history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®
                    role_name = 'ç”¨æˆ·' if msg.role == 'user' else 'åŠ©æ‰‹'
                    history_parts.append(f'{role_name}: {msg.content}')
                history_context = '\n'.join(history_parts)
            
            # æ­¥éª¤4: å¡«å……æç¤ºè¯æ¨¡æ¿
            full_prompt = PROMPT_TEMPLATE.format(
                knowledge_context=knowledge_context,
                user_question=request.question,
                history_context=history_context,
            )
            
            # æ­¥éª¤5: è°ƒç”¨å¤§æ¨¡å‹
            has_image = bool(request.image_url or request.image_base64)
            
            if has_image:
                # å¤šæ¨¡æ€å¯¹è¯
                answer = await self.aliyun_service.chat_with_image(
                    text=full_prompt,
                    image_url=request.image_url,
                    image_base64=request.image_base64,
                    history=None,  # å†å²å·²ç»åœ¨promptä¸­
                )
                model_used = settings.default_vl_model
            else:
                # çº¯æ–‡æœ¬å¯¹è¯
                messages = [Message(role='user', content=full_prompt)]
                answer = await self.aliyun_service.chat(messages)
                model_used = settings.default_llm_model
            
            # æ­¥éª¤6: è¯„ä¼°ç½®ä¿¡åº¦
            confidence = self._evaluate_confidence(
                answer=answer,
                knowledge_found=bool(knowledge_sources),
            )
            
            # æ„å»ºå“åº”
            response = ChatResponse(
                answer=answer,
                confidence=confidence,
                knowledge_sources=knowledge_sources,
                llm_model=model_used,
                has_image=has_image,
                out_of_scope=False,
                relevance_score=max_relevance_score,
            )
            
            logger.info(
                f'RAGå¯¹è¯å®Œæˆ - é—®é¢˜: {request.question[:50]}..., '
                f'ç½®ä¿¡åº¦: {confidence}, ä½¿ç”¨çŸ¥è¯†åº“: {request.use_knowledge_base}'
            )
            
            return response
            
        except Exception as e:
            logger.error(f'RAGå¯¹è¯å¤±è´¥: {e}')
            # è¿”å›å‹å¥½çš„é”™è¯¯å“åº”
            return ChatResponse(
                answer=f'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†é”™è¯¯ï¼š{str(e)}',
                confidence='ä½',
                knowledge_sources=[],
                llm_model='error',
                has_image=False,
                out_of_scope=False,
                relevance_score=None,
            )
    
    def _generate_out_of_scope_message(
        self,
        question: str,
        max_score: float,
    ) -> str:
        """ç”Ÿæˆè¶…å‡ºçŸ¥è¯†åº“èŒƒå›´çš„å‹å¥½æç¤º.
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            max_score: æœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•°
            
        Returns:
            å‹å¥½çš„æç¤ºæ¶ˆæ¯
        """
        message = f"""æŠ±æ­‰ï¼Œæ‚¨çš„é—®é¢˜ä¼¼ä¹è¶…å‡ºäº†æˆ‘çš„ä¸“ä¸šçŸ¥è¯†åº“èŒƒå›´ã€‚

ğŸ“š **æˆ‘çš„ä¸“ä¸šé¢†åŸŸ**
æˆ‘ç›®å‰ä¸“æ³¨äºä»¥ä¸‹é¢†åŸŸçš„ä¸“ä¸šå’¨è¯¢ï¼š
â€¢ æŠ—è¡°è€ç§‘å­¦ä¸ç­–ç•¥
â€¢ å¥åº·ç®¡ç†ä¸é•¿å¯¿ç ”ç©¶  
â€¢ ç»†èƒç”Ÿç‰©å­¦ä¸å†ç”ŸåŒ»å­¦
â€¢ è¥å…»å­¦ä¸è¿åŠ¨ç§‘å­¦
â€¢ è¡°è€ç›¸å…³çš„åŒ»å­¦ç ”ç©¶

ğŸ’¡ **å»ºè®®æ‚¨**
1. å’¨è¯¢ç›¸å…³é¢†åŸŸçš„ä¸“ä¸šåŒ»ç”Ÿæˆ–ä¸“å®¶
2. é‡æ–°æè¿°é—®é¢˜ï¼Œçœ‹æ˜¯å¦ä¸æŠ—è¡°è€å¥åº·ç›¸å…³
3. æŸ¥çœ‹æˆ‘çš„çŸ¥è¯†åº“æ¶µç›–èŒƒå›´

â“ **æ‚¨çš„é—®é¢˜**: {question}

å¦‚æœæ‚¨è®¤ä¸ºè¿™ä¸ªé—®é¢˜åº”è¯¥å±äºæˆ‘çš„ä¸“ä¸šèŒƒå›´ï¼Œè¯·å°è¯•æ¢ä¸ªæ–¹å¼æé—®ï¼Œæˆ–æä¾›æ›´å¤šèƒŒæ™¯ä¿¡æ¯ã€‚

---
ç›¸å…³æ€§è¯„åˆ†: {max_score:.2f} / é˜ˆå€¼: {settings.knowledge_relevance_threshold}"""
        
        return message
    
    def _evaluate_confidence(
        self,
        answer: str,
        knowledge_found: bool,
    ) -> Literal['é«˜', 'ä¸­', 'ä½']:
        """è¯„ä¼°å›ç­”ç½®ä¿¡åº¦.
        
        Args:
            answer: æ¨¡å‹å›ç­”
            knowledge_found: æ˜¯å¦æ‰¾åˆ°ç›¸å…³çŸ¥è¯†
            
        Returns:
            ç½®ä¿¡åº¦ç­‰çº§
        """
        # ç®€å•çš„å¯å‘å¼è§„åˆ™
        if not knowledge_found:
            return 'ä½'
        
        # æ£€æŸ¥å›ç­”é•¿åº¦
        if len(answer) < 20:
            return 'ä½'
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸ç¡®å®šè¯æ±‡
        uncertain_words = ['å¯èƒ½', 'ä¹Ÿè®¸', 'å¤§æ¦‚', 'ä¸ç¡®å®š', 'ä¸å¤ªæ¸…æ¥š']
        if any(word in answer for word in uncertain_words):
            return 'ä¸­'
        
        return 'é«˜'
    
    async def chat_simple(
        self,
        question: str,
        use_knowledge: bool = True,
    ) -> str:
        """ç®€åŒ–çš„å¯¹è¯æ¥å£.
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            use_knowledge: æ˜¯å¦ä½¿ç”¨çŸ¥è¯†åº“
            
        Returns:
            å›ç­”å†…å®¹
        """
        request = ChatRequest(
            question=question,
            use_knowledge_base=use_knowledge,
        )
        response = await self.chat(request)
        return response.answer

